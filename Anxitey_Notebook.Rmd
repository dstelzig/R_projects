---
title: "R Notebook of Social Anxiety Regression"
author: "David Stelzig"
output: html_notebook
---

# Introduction

This is an R Notebook that demonstrates the basic analysis and regression of the social anxiety dataset: https://www.kaggle.com/datasets/natezhang123/social-anxiety-dataset

## Dataset

The data contain 19 characteristic, numeric and character features contributing to the target variable *anxiety_level*.

## Topics

The notebook includes the following steps:

-   Import of libraries, loading the data and **cleaning** the data (missing values, duplicates ...)
-   **Exploratory Data Analysis**
-   **Training** of a different regression models


# 1. Load Libraries and import the data

```{r}
library(tidyverse)
library(caret)
library(randomForest)
library(e1071)
library(ggplot2)
library(corrplot)
library(gbm)
library(class)
library(tidyr)
library(dplyr)

social_anxiety_data <- read.csv("C:/Users/Sabrina/OneDrive/Desktop/David_work/R/enhanced_anxiety_dataset.csv")
head(social_anxiety_data)

```
Rename the columns for better readability:

```{r}
colnames(social_anxiety_data) <- c("age", "gender", "occpuation", "sleep_hours", "physical_activity", 
                             "caffeine", "alcohol", "smoking",
                             "family","stress","heart_rate","breathing_rate","sweating",
                             "dizziness","medication","therapy","major_event","diet","anxiety_level")
head(social_anxiety_data)
```
# 2. Data Cleaning and Processing

```{r}
# Check for missing values
colSums(is.na(social_anxiety_data))

# Check data structure
str(social_anxiety_data)

```

The dataset does **not** contain missing values and classes are characters, numeric or integers. 
```{r}
#Check for duplicates
duplicate_rows <- duplicated(social_anxiety_data)
sum(duplicate_rows)
```
```{r}
# Summary statistics
summary(social_anxiety_data)
```

Problem: For downstream *Machine Learning* models, the data need to be converted to numerical features.

```{r}
# Convert categorical variables to factors
social_anxiety_data <- social_anxiety_data %>%
  mutate_if(is.character, as.factor)


#statistics
summary(social_anxiety_data)
```

Use the near-zero variation feature method in R to obtain critical columns and drop them because they can lead to *overfitting* and can complicate *model interpretability*.

```{r}
# Check for near-zero variance predictors 
# NZV features usually only display minimal variability and can lead to overfitting and complicate model interpretability
nzv_features <- nearZeroVar(social_anxiety_data, saveMetrics = TRUE)

# Display features with near-zero variance
nzv_features[nzv_features$nzv, ]
```

No NZV features were identified.

The data are now ready for further analysis.

## 3. Exploratory Data Analysis and Visualization

One of the first things to check is the distribution of the target class **anxiety_level**. If the population is very imbalanced, then other techniques need to be applied to rebalance the dataset. A good visualization is the histogram plot.

```{r}
ggplot(social_anxiety_data, aes(x = anxiety_level)) +
  geom_histogram(binwidth = 1, fill = "#030e45", color = "black", alpha = 0.5)
  labs(title = "Distribution of Social Anxiety Scores",
       x = "Social Anxiety Score",
       y = "Frequency") +
  theme_minimal(base_size = 14) +
  theme(
    plot.title = element_text(hjust = 0.5, face = "bold", size = 18),
    axis.title.x = element_text(size = 14),
    axis.title.y = element_text(size = 14),
    axis.text.x = element_text(size = 12),
    axis.text.y = element_text(size = 12),
    panel.grid.minor = element_blank(),
    panel.grid.major.x = element_line(color = "gray90"),
    panel.grid.major.y = element_line(color = "gray90")
  )
```

As we can see, most people included in the dataset have anxiety_levels between 3 and 4.
Check the distribution of the different factors.
```{r}
library(gridExtra)
library(viridis)
library(ggpubr)
# Identify numerical columns
numeric_vars <- names(social_anxiety_data)[sapply(social_anxiety_data, is.numeric)]

# Create a list to store plots
hist_plots <- list()
color_palette <- viridis::magma(length(numeric_vars), begin = 0.2, end = 0.9)
# Generate histograms for each numerical variable
for (i in seq_along(numeric_vars)) {
  var <- numeric_vars[i]
  p <- ggplot(social_anxiety_data, aes_string(x = var)) +
    geom_histogram(bins = 50, fill = color_palette[i], color = "black", alpha = 0.7) +
    theme_minimal(base_size = 10) +
    labs(title = paste("Distribution of", var), x = var, y = "Count") +
    theme(plot.title = element_text(hjust = 0.5, face = "bold", size = 7),
          axis.text = element_text(size = 5),
          axis.title = element_text(size = 5))
  
  hist_plots[[var]] <- p
}


# Arrange plots in a grid
grid.arrange(grobs = hist_plots, ncol = 4)

```
Several key takeaways from the histograms:
- The age of the people is well distributed
- Most people sleep around 7 hours
- The therapy time is very low
- Most people rate the quality of their diet really low.
- Many people have a high stress level.

```{r}
library(ggpubr)
bar_plots <- list()
selected_categorical_vars <- c("dizziness", "smoking", "gender", "family", "medication","occpuation")
categorical_palette <- viridis::viridis(length(numeric_vars), begin = 0.2, end = 0.9)
for (i in seq_along(selected_categorical_vars)) {
  var <- selected_categorical_vars[i]
  if (var %in% names(social_anxiety_data)) {
    p <- ggplot(social_anxiety_data, aes_string(x = var)) +
      geom_bar(fill = categorical_palette[i], color = "black", alpha = 0.7) +
      theme_minimal(base_size = 10) +
      labs(title = paste("Distribution of", var), x = var, y = "Count") +
      theme(plot.title = element_text(hjust = 0.5, face = "bold", size = 12),
            axis.text = element_text(size = 8, angle = 45, hjust = 1),
            axis.title = element_text(size = 10))
    
    bar_plots[[var]] <- p
  }
}

# Arrange plots in a grid
grid.arrange(grobs = bar_plots, ncol = 3)
```
Takeaeay from categorical features:
- The dataset is well balanced for all features
```{r}
categorical_vars <- names(social_anxiety_data)[sapply(social_anxiety_data, is.factor) | sapply(social_anxiety_data, is.character)]
encoded_data <- social_anxiety_data
for (cat_var in categorical_vars) {
  if (cat_var %in% names(encoded_data)) {
    encoded_data[[cat_var]] <- as.numeric(as.factor(encoded_data[[cat_var]]))
  }
}

# Compute correlation matrix
correlation_matrix <- cor(encoded_data, use = "pairwise.complete.obs")

# Plot heatmap of correlation matrix
ggheatmap <- ggcorrplot::ggcorrplot(correlation_matrix, 
                                    lab = FALSE, 
                                    #lab_size = 3, 
                                    colors = viridis::viridis(3), 
                                    show.legend = TRUE, 
                                    title = "Correlation Heatmap", 
                                    ggtheme = theme_minimal(),
                                    type = "lower", 
                                    outline.col = "white") +
                                    theme(plot.title = element_text(hjust = 0.5, face = "bold", size = 12),
                                              axis.text = element_text(size = 6, angle = 45, hjust = 1))

# Display heatmap
print(ggheatmap)

```
Based on this correlation map we can state the following hypothesis:
- **stress** correlates positively with **anxiety_level**
- **therapy** correlates positively with **anxiety_level**
- **sleep_hours** correlates negatively with **anxiety_level**
- **family history** correlates positively with **therapy**


# 3. Model Building, Machine Learning and Evalution

# Question 1: Can we predict social anxiety scores based on other variables?
# Regression

## 3.1 Split the data

```{r}
# Split data into training and testing sets
set.seed(123)
trainIndex <- createDataPartition(social_anxiety_data$anxiety_level, p = 0.8, list = FALSE)
train_data <- social_anxiety_data[trainIndex, ]
test_data <- social_anxiety_data[-trainIndex, ]

# Ensure class is factor
str(train_data)
```


## 3.2 Train the model 

**Linear Regression**

```{r}
# Load required libraries
library(randomForest)
library(gbm)
library(caret)
library(ggplot2)
library(e1071)  # For SVM
library(class)   # For KNN
library(glmnet)  # For ElasticNet

# Assuming you have already loaded and split the dataset into train_data and test_data

# Linear Regression
linear_model <- lm(anxiety_level ~ ., data = train_data)
linear_predictions <- predict(linear_model, newdata = test_data)
linear_r2 <- cor(test_data$anxiety_level, linear_predictions)^2  # R-squared

# Random Forest Regression
#rf_model_reg <- randomForest(anxiety_level ~ ., data = train_data)
#rf_predictions_reg <- predict(rf_model_reg, newdata = test_data)
#rf_r2 <- cor(test_data$anxiety_level, rf_predictions_reg)^2  # R-squared

# Gradient Boosting Regression
gbm_model_reg <- gbm(anxiety_level ~ ., data = train_data, distribution = "gaussian", 
                     n.trees = 100, interaction.depth = 3, shrinkage = 0.1)
gbm_predictions_reg <- predict(gbm_model_reg, newdata = test_data, n.trees = 100)
gbm_r2 <- cor(test_data$anxiety_level, gbm_predictions_reg)^2  # R-squared

# Support Vector Regression (SVR)
svr_model <- svm(anxiety_level ~ ., data = train_data)
svr_predictions <- predict(svr_model, newdata = test_data)
svr_r2 <- cor(test_data$anxiety_level, svr_predictions)^2  # R-squared

# K-Nearest Neighbors (KNN) Regression
#knn_model <- train(anxiety_level ~ ., data = train_data, method = "knn", tuneLength = 10)
#knn_predictions <- predict(knn_model, newdata = test_data)
#knn_r2 <- cor(test_data$anxiety_level, knn_predictions)^2  # R-squared

# ElasticNet Regression
elasticnet_model <- cv.glmnet(as.matrix(train_data[, -which(names(train_data) == "anxiety_level")]), 
                              train_data$anxiety_level, alpha = 0.5)
elasticnet_predictions <- predict(elasticnet_model, s = "lambda.min", newx = as.matrix(test_data[, -which(names(test_data) == "anxiety_level")]))
elasticnet_r2 <- cor(test_data$anxiety_level, elasticnet_predictions)^2  # R-squared

# Print the R-squared values
print(paste("Linear Regression R²:", linear_r2))
#print(paste("Random Forest R²:", rf_r2))
print(paste("GBM R²:", gbm_r2))
print(paste("SVR R²:", svr_r2))
#print(paste("KNN R²:", knn_r2))
print(paste("ElasticNet R²:", elasticnet_r2))

# Prepare data for plotting
model_names <- c("Linear Regression", "GBM", "SVR", "ElasticNet")
r2_values <- c(linear_r2, gbm_r2, svr_r2, elasticnet_r2)

# Create a data frame for plotting
r2_df <- data.frame(Model = model_names, R2 = r2_values)


```
```{r}

ggplot(r2_df, aes(x = Model, y = R2, fill = Model)) +
  geom_bar(stat = "identity", color = "black", show.legend = FALSE, width = 0.7) + # Adjusted bar width
  geom_text(aes(label = round(R2, 3)), vjust = 2, size = 4, color = "gray20") + # Adjusted text size, color, and rounding
  labs(
    title = "R² Comparison of Regression Models",
    x = "Regression Model", # More descriptive x-axis label
    y = "Coefficient of Determination (R²)" # More descriptive y-axis label
  ) +
  theme_minimal(base_size = 14) + # Increased base size for better readability
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1, size = 10), # Adjusted x-axis text size
    axis.title = element_text(size = 10, face = "bold"), # Bold axis titles
    plot.title = element_text(size = 13, face = "bold", hjust = 0.5), # Centered and bold title
    panel.grid.major.y = element_line(color = "gray90"), # Added subtle horizontal grid lines
    panel.grid.minor.y = element_blank(), # Removed minor grid lines
    panel.grid.major.x = element_blank() # Removed vertical grid lines
  ) +
  scale_fill_brewer(palette = "magma") # Use a visually appealing color palette
```

## 3.3 Evaluation

Analyze the feature importance:

```{r}
library(gbm)
library(knitr)

# Assuming gbm_model_reg is your trained gbm regression model

var_importance <- summary(gbm_model_reg, n.trees = gbm_model_reg$n.trees) # Use all trees

# Prettier output using kable
if (nrow(var_importance) > 0) {
  ggplot(var_importance, aes(x = reorder(var, -rel.inf), y = rel.inf, fill = rel.inf)) + 
    geom_bar(stat = "identity", color = "black") +
    coord_flip() +  # Flip coordinates for better readability
    scale_fill_viridis(option = "viridis", direction = -1) +  # Apply magma color palette
    labs(title = "Variable Importance from GBM Model", 
         x = "Variable", 
         y = "Relative Influence") +
    theme_minimal(base_size = 12) +
    theme(axis.text = element_text(size = 10), 
          axis.title = element_text(size = 12),
          plot.title = element_text(hjust = 0.5, size = 14, face = "bold"))
  
} else {
  print("No variable importance information available.")
}

```
```{r}

ggplot(data.frame(observed = test_data$anxiety_level, predicted = gbm_predictions_reg), aes(x = observed, y = predicted)) +
  geom_point() +
  geom_smooth(method = "lm", se = FALSE, color = "red") +
  labs(title = "Predicted vs. Observed Social Anxiety Scores",
       x = "Observed Social Anxiety",
       y = "Predicted Social Anxiety") +
  theme_minimal()
```
